{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":16707,"status":"ok","timestamp":1702242767179,"user":{"displayName":"Cristian Lazo","userId":"16455738793233122743"},"user_tz":300},"id":"A8Tzt8MakSu9","outputId":"2e22bfa1-8859-48d4-a27b-24f437d0054f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/my_drive/\n"]}],"source":["from google.colab import drive\n","\n","drive.mount(\"/content/my_drive/\")"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":615,"status":"ok","timestamp":1702242767789,"user":{"displayName":"Cristian Lazo","userId":"16455738793233122743"},"user_tz":300},"id":"PIoabVWykVa_","outputId":"c8e73f10-3380-4b0d-e49b-131a0ea18213"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/my_drive/MyDrive/Neurips23/Integrating-Spatial-Transform-Networks-with-PaDim-Architecture/notebooks\n"]}],"source":["cd /content/my_drive/MyDrive/Neurips23/Integrating-Spatial-Transform-Networks-with-PaDim-Architecture/notebooks/"]},{"cell_type":"code","source":["!git status"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lAmDkNpFk2xJ","executionInfo":{"status":"ok","timestamp":1702242857018,"user_tz":300,"elapsed":77200,"user":{"displayName":"Cristian Lazo","userId":"16455738793233122743"}},"outputId":"5c80cc4b-b201-4b5c-f4ca-fd7ccf6d5235"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Refresh index: 100% (119/119), done.\n","On branch exp-cristian\n","Your branch is up to date with 'origin/exp-cristian'.\n","\n","Changes to be committed:\n","  (use \"git restore --staged <file>...\" to unstage)\n","\t\u001b[32mmodified:   ../.gitignore\u001b[m\n","\t\u001b[32mmodified:   Train padim.ipynb\u001b[m\n","\t\u001b[32mmodified:   train_stn_model.py\u001b[m\n","\t\u001b[32mdeleted:    ../results/checkpoint_best_model.pth\u001b[m\n","\t\u001b[32mmodified:   ../src/padim_model/dataloader.py\u001b[m\n","\t\u001b[32mmodified:   ../src/padim_model/train.py\u001b[m\n","\t\u001b[32mmodified:   ../src/stn_model/dataloader.py\u001b[m\n","\t\u001b[32mmodified:   ../src/stn_model/train.py\u001b[m\n","\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":5121,"status":"ok","timestamp":1702231277239,"user":{"displayName":"Cristian Lazo","userId":"16455738793233122743"},"user_tz":300},"id":"QQ83mxj_mJYo","colab":{"base_uri":"https://localhost:8080/"},"outputId":"c272b028-9a7d-4e1d-bcb7-c5302a748a29"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting pytorch_msssim\n","  Downloading pytorch_msssim-1.0.0-py3-none-any.whl (7.7 kB)\n","Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from pytorch_msssim) (2.1.0+cu118)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->pytorch_msssim) (3.13.1)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->pytorch_msssim) (4.5.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->pytorch_msssim) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->pytorch_msssim) (3.2.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->pytorch_msssim) (3.1.2)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->pytorch_msssim) (2023.6.0)\n","Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch->pytorch_msssim) (2.1.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->pytorch_msssim) (2.1.3)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->pytorch_msssim) (1.3.0)\n","Installing collected packages: pytorch_msssim\n","Successfully installed pytorch_msssim-1.0.0\n"]}],"source":["!pip install pytorch_msssim"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":8397,"status":"ok","timestamp":1702231285632,"user":{"displayName":"Cristian Lazo","userId":"16455738793233122743"},"user_tz":300},"id":"KlK0Jo9ynKzB","colab":{"base_uri":"https://localhost:8080/"},"outputId":"12cb216b-7029-4c19-890a-eeb06ec2a54d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting wandb\n","  Downloading wandb-0.16.1-py3-none-any.whl (2.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m22.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: Click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb) (8.1.7)\n","Collecting GitPython!=3.1.29,>=1.0.0 (from wandb)\n","  Downloading GitPython-3.1.40-py3-none-any.whl (190 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.6/190.6 kB\u001b[0m \u001b[31m25.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.31.0)\n","Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (5.9.5)\n","Collecting sentry-sdk>=1.0.0 (from wandb)\n","  Downloading sentry_sdk-1.38.0-py2.py3-none-any.whl (252 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m252.8/252.8 kB\u001b[0m \u001b[31m33.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting docker-pycreds>=0.4.0 (from wandb)\n","  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n","Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from wandb) (6.0.1)\n","Collecting setproctitle (from wandb)\n","  Downloading setproctitle-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb) (67.7.2)\n","Requirement already satisfied: appdirs>=1.4.3 in /usr/local/lib/python3.10/dist-packages (from wandb) (1.4.4)\n","Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.20.3)\n","Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n","Collecting gitdb<5,>=4.0.1 (from GitPython!=3.1.29,>=1.0.0->wandb)\n","  Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2023.11.17)\n","Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb)\n","  Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n","Installing collected packages: smmap, setproctitle, sentry-sdk, docker-pycreds, gitdb, GitPython, wandb\n","Successfully installed GitPython-3.1.40 docker-pycreds-0.4.0 gitdb-4.0.11 sentry-sdk-1.38.0 setproctitle-1.3.3 smmap-5.0.1 wandb-0.16.1\n"]}],"source":["!pip install --upgrade wandb"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zXtfqxeFkVYe","outputId":"71bfe65c-f3ac-425a-96a6-aba59a312695","executionInfo":{"status":"ok","timestamp":1702235906473,"user_tz":300,"elapsed":2941761,"user":{"displayName":"Cristian Lazo","userId":"16455738793233122743"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["args.device: 0\n","Namespace(data_path='../data', experiment_name='exp-padim', batch_size=128, learning_rate=0.0005, path_results='../results/padim_results', arch='resnet18', use_stn=0, use_stn_mask=0, path_model_stn='../results/models/v1_mse/checkpoint_best_model_ssim_weight_08.pth', device='0')\n","\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mcristian-ml\u001b[0m (\u001b[33mml_projects\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.1\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/my_drive/MyDrive/Neurips23/Integrating-Spatial-Transform-Networks-with-PaDim-Architecture/notebooks/wandb/run-20231210_182930-6wiuj3k4\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mexp-padim\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/ml_projects/neurips_23_padim\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/ml_projects/neurips_23_padim/runs/6wiuj3k4\u001b[0m\n","/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n","  warnings.warn(msg)\n","Training..\n","| feature extraction | train | bottle |: 100% 2/2 [00:07<00:00,  3.98s/it]\n","| feature extraction | test | bottle |: 100% 1/1 [00:02<00:00,  2.98s/it]\n","bottle  test image ROCAUC: 0.996\n","[0 0 0 ... 0 0 0]\n","[0.00753963 0.0075405  0.00754277 ... 0.01371989 0.01372038 0.01372051]\n","bottle  test pixel ROCAUC: 0.984\n","Training..\n","| feature extraction | train | cable |: 100% 2/2 [00:11<00:00,  5.76s/it]\n","| feature extraction | test | cable |: 100% 2/2 [00:08<00:00,  4.11s/it]\n","cable  test image ROCAUC: 0.843\n","[0 0 0 ... 0 0 0]\n","[0.10823047 0.10867111 0.10952523 ... 0.06995647 0.0697539  0.06962644]\n","cable  test pixel ROCAUC: 0.968\n","Training..\n","| feature extraction | train | capsule |: 100% 2/2 [00:10<00:00,  5.42s/it]\n","| feature extraction | test | capsule |: 100% 2/2 [00:07<00:00,  3.59s/it]\n","capsule  test image ROCAUC: 0.866\n","[0 0 0 ... 0 0 0]\n","[0.0486411  0.04868125 0.0487327  ... 0.02358977 0.02362772 0.02364036]\n","capsule  test pixel ROCAUC: 0.986\n","Training..\n","| feature extraction | train | carpet |: 100% 3/3 [00:14<00:00,  4.85s/it]\n","| feature extraction | test | carpet |: 100% 1/1 [03:05<00:00, 185.84s/it]\n","carpet  test image ROCAUC: 0.984\n","[0 0 0 ... 0 0 0]\n","[0.08908552 0.090265   0.09258392 ... 0.13426618 0.13314778 0.13255565]\n","carpet  test pixel ROCAUC: 0.991\n","Training..\n","| feature extraction | train | grid |: 100% 3/3 [01:11<00:00, 24.00s/it]\n","| feature extraction | test | grid |: 100% 1/1 [01:56<00:00, 116.78s/it]\n","grid  test image ROCAUC: 0.918\n","[0 0 0 ... 0 0 0]\n","[0.14217216 0.14234376 0.14273079 ... 0.12940553 0.12889801 0.12864706]\n","grid  test pixel ROCAUC: 0.930\n","Training..\n","| feature extraction | train | hazelnut |: 100% 4/4 [00:44<00:00, 11.08s/it]\n","| feature extraction | test | hazelnut |: 100% 1/1 [02:44<00:00, 164.58s/it]\n","hazelnut  test image ROCAUC: 0.825\n","[0 0 0 ... 0 0 0]\n","[0.16760486 0.16707633 0.16599354 ... 0.05692344 0.05604959 0.05559476]\n","hazelnut  test pixel ROCAUC: 0.984\n","Training..\n","| feature extraction | train | leather |: 100% 2/2 [00:49<00:00, 24.98s/it]\n","| feature extraction | test | leather |: 100% 1/1 [03:23<00:00, 203.47s/it]\n","leather  test image ROCAUC: 0.992\n","[0 0 0 ... 0 0 0]\n","[0.06415299 0.06444909 0.06505004 ... 0.03395756 0.03399088 0.03400746]\n","leather  test pixel ROCAUC: 0.991\n","Training..\n","| feature extraction | train | metal_nut |: 100% 2/2 [00:44<00:00, 22.30s/it]\n","| feature extraction | test | metal_nut |: 100% 1/1 [02:27<00:00, 147.43s/it]\n","metal_nut  test image ROCAUC: 0.927\n","[0 0 0 ... 0 0 0]\n","[0.01664655 0.01659841 0.01650501 ... 0.00803647 0.00801718 0.00800727]\n","metal_nut  test pixel ROCAUC: 0.974\n","Training..\n","| feature extraction | train | pill |: 100% 3/3 [00:45<00:00, 15.33s/it]\n","| feature extraction | test | pill |: 100% 2/2 [04:23<00:00, 131.87s/it]\n","pill  test image ROCAUC: 0.810\n","[0 0 0 ... 0 0 0]\n","[0.06199887 0.06279621 0.06435017 ... 0.07370403 0.07298779 0.0726073 ]\n","pill  test pixel ROCAUC: 0.960\n","Training..\n","| feature extraction | train | screw |: 100% 3/3 [01:19<00:00, 26.52s/it]\n","| feature extraction | test | screw |: 100% 2/2 [03:53<00:00, 117.00s/it]\n","screw  test image ROCAUC: 0.785\n","[0 0 0 ... 0 0 0]\n","[0.11002766 0.11023457 0.1106715  ... 0.03299421 0.03275492 0.03263862]\n","screw  test pixel ROCAUC: 0.982\n","Training..\n","| feature extraction | train | tile |: 0it [00:00, ?it/s]\n","Traceback (most recent call last):\n","  File \"/content/my_drive/MyDrive/Neurips23/Integrating-Spatial-Transform-Networks-with-PaDim-Architecture/notebooks/train_padim.py\", line 75, in <module>\n","    main_process()\n","  File \"/content/my_drive/MyDrive/Neurips23/Integrating-Spatial-Transform-Networks-with-PaDim-Architecture/notebooks/train_padim.py\", line 74, in main_process\n","    train(args)\n","  File \"/content/my_drive/MyDrive/Neurips23/Integrating-Spatial-Transform-Networks-with-PaDim-Architecture/notebooks/train_padim.py\", line 64, in train\n","    fig_pixel_rocauc,fig_img_rocauc,total_roc_auc,total_pixel_roc_auc,fig = padim_train.start(CLASS_NAMES,\n","  File \"/content/my_drive/MyDrive/Neurips23/Integrating-Spatial-Transform-Networks-with-PaDim-Architecture/notebooks/../src/padim_model/train.py\", line 174, in start\n","    outputs = []\n","RuntimeError: torch.cat(): expected a non-empty list of Tensors\n","Traceback (most recent call last):\n","  File \"/content/my_drive/MyDrive/Neurips23/Integrating-Spatial-Transform-Networks-with-PaDim-Architecture/notebooks/train_padim.py\", line 75, in <module>\n","    main_process()\n","  File \"/content/my_drive/MyDrive/Neurips23/Integrating-Spatial-Transform-Networks-with-PaDim-Architecture/notebooks/train_padim.py\", line 74, in main_process\n","    train(args)\n","  File \"/content/my_drive/MyDrive/Neurips23/Integrating-Spatial-Transform-Networks-with-PaDim-Architecture/notebooks/train_padim.py\", line 64, in train\n","    fig_pixel_rocauc,fig_img_rocauc,total_roc_auc,total_pixel_roc_auc,fig = padim_train.start(CLASS_NAMES,\n","  File \"/content/my_drive/MyDrive/Neurips23/Integrating-Spatial-Transform-Networks-with-PaDim-Architecture/notebooks/../src/padim_model/train.py\", line 174, in start\n","    outputs = []\n","RuntimeError: torch.cat(): expected a non-empty list of Tensors\n","\u001b[34m\u001b[1mwandb\u001b[0m: \n","\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n","\u001b[34m\u001b[1mwandb\u001b[0m:    bottle_image_ROCAUC ▁\n","\u001b[34m\u001b[1mwandb\u001b[0m:    bottle_pixel_ROCAUC ▁\n","\u001b[34m\u001b[1mwandb\u001b[0m:     cable_image_ROCAUC ▁\n","\u001b[34m\u001b[1mwandb\u001b[0m:     cable_pixel_ROCAUC ▁\n","\u001b[34m\u001b[1mwandb\u001b[0m:   capsule_image_ROCAUC ▁\n","\u001b[34m\u001b[1mwandb\u001b[0m:   capsule_pixel_ROCAUC ▁\n","\u001b[34m\u001b[1mwandb\u001b[0m:    carpet_image_ROCAUC ▁\n","\u001b[34m\u001b[1mwandb\u001b[0m:    carpet_pixel_ROCAUC ▁\n","\u001b[34m\u001b[1mwandb\u001b[0m:      grid_image_ROCAUC ▁\n","\u001b[34m\u001b[1mwandb\u001b[0m:      grid_pixel_ROCAUC ▁\n","\u001b[34m\u001b[1mwandb\u001b[0m:  hazelnut_image_ROCAUC ▁\n","\u001b[34m\u001b[1mwandb\u001b[0m:  hazelnut_pixel_ROCAUC ▁\n","\u001b[34m\u001b[1mwandb\u001b[0m:   leather_image_ROCAUC ▁\n","\u001b[34m\u001b[1mwandb\u001b[0m:   leather_pixel_ROCAUC ▁\n","\u001b[34m\u001b[1mwandb\u001b[0m: metal_nut_image_ROCAUC ▁\n","\u001b[34m\u001b[1mwandb\u001b[0m: metal_nut_pixel_ROCAUC ▁\n","\u001b[34m\u001b[1mwandb\u001b[0m:      pill_image_ROCAUC ▁\n","\u001b[34m\u001b[1mwandb\u001b[0m:      pill_pixel_ROCAUC ▁\n","\u001b[34m\u001b[1mwandb\u001b[0m:     screw_image_ROCAUC ▁\n","\u001b[34m\u001b[1mwandb\u001b[0m:     screw_pixel_ROCAUC ▁\n","\u001b[34m\u001b[1mwandb\u001b[0m: \n","\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n","\u001b[34m\u001b[1mwandb\u001b[0m:    bottle_image_ROCAUC 0.99603\n","\u001b[34m\u001b[1mwandb\u001b[0m:    bottle_pixel_ROCAUC 0.98405\n","\u001b[34m\u001b[1mwandb\u001b[0m:     cable_image_ROCAUC 0.84258\n","\u001b[34m\u001b[1mwandb\u001b[0m:     cable_pixel_ROCAUC 0.96777\n","\u001b[34m\u001b[1mwandb\u001b[0m:   capsule_image_ROCAUC 0.86598\n","\u001b[34m\u001b[1mwandb\u001b[0m:   capsule_pixel_ROCAUC 0.98613\n","\u001b[34m\u001b[1mwandb\u001b[0m:    carpet_image_ROCAUC 0.98395\n","\u001b[34m\u001b[1mwandb\u001b[0m:    carpet_pixel_ROCAUC 0.99066\n","\u001b[34m\u001b[1mwandb\u001b[0m:      grid_image_ROCAUC 0.91813\n","\u001b[34m\u001b[1mwandb\u001b[0m:      grid_pixel_ROCAUC 0.92969\n","\u001b[34m\u001b[1mwandb\u001b[0m:  hazelnut_image_ROCAUC 0.825\n","\u001b[34m\u001b[1mwandb\u001b[0m:  hazelnut_pixel_ROCAUC 0.98429\n","\u001b[34m\u001b[1mwandb\u001b[0m:   leather_image_ROCAUC 0.99219\n","\u001b[34m\u001b[1mwandb\u001b[0m:   leather_pixel_ROCAUC 0.9907\n","\u001b[34m\u001b[1mwandb\u001b[0m: metal_nut_image_ROCAUC 0.92717\n","\u001b[34m\u001b[1mwandb\u001b[0m: metal_nut_pixel_ROCAUC 0.97406\n","\u001b[34m\u001b[1mwandb\u001b[0m:      pill_image_ROCAUC 0.8096\n","\u001b[34m\u001b[1mwandb\u001b[0m:      pill_pixel_ROCAUC 0.95971\n","\u001b[34m\u001b[1mwandb\u001b[0m:     screw_image_ROCAUC 0.78459\n","\u001b[34m\u001b[1mwandb\u001b[0m:     screw_pixel_ROCAUC 0.98188\n","\u001b[34m\u001b[1mwandb\u001b[0m: \n","\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mexp-padim\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/ml_projects/neurips_23_padim/runs/6wiuj3k4\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: ️⚡ View job at \u001b[34m\u001b[4mhttps://wandb.ai/ml_projects/neurips_23_padim/jobs/QXJ0aWZhY3RDb2xsZWN0aW9uOjEyMjQ1MzU5Nw==/version_details/v0\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 10 media file(s), 2 artifact file(s) and 0 other file(s)\n","\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20231210_182930-6wiuj3k4/logs\u001b[0m\n"]}],"source":["! python train_padim.py --arch resnet18 --use_stn_mask 0 --use_stn 0 --path_model_stn ../results/models/v1_mse/checkpoint_best_model_ssim_weight_08.pth"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JN2v9qQZwP9a","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1702236673613,"user_tz":300,"elapsed":767144,"user":{"displayName":"Cristian Lazo","userId":"16455738793233122743"}},"outputId":"0d578ae9-f103-49b3-a3eb-d6d669a9011e"},"outputs":[{"output_type":"stream","name":"stdout","text":["args.device: 0\n","Namespace(data_path='../data', experiment_name='exp-padim', batch_size=128, learning_rate=0.0005, path_results='../results/padim_results', arch='resnet18', use_stn=1, use_stn_mask=1, path_model_stn='../results/models/v1_mse/checkpoint_best_model_ssim_weight_08.pth', device='0')\n","\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mcristian-ml\u001b[0m (\u001b[33mml_projects\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.1\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/my_drive/MyDrive/Neurips23/Integrating-Spatial-Transform-Networks-with-PaDim-Architecture/notebooks/wandb/run-20231210_191833-57gnqllf\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mexp-padim\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/ml_projects/neurips_23_padim\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/ml_projects/neurips_23_padim/runs/57gnqllf\u001b[0m\n","/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n","  warnings.warn(msg)\n","Training..\n","| feature extraction | train | bottle |: 100% 2/2 [00:08<00:00,  4.10s/it]\n","| feature extraction | test | bottle |:   0% 0/1 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:4358: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:4296: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.\n","  warnings.warn(\n","| feature extraction | test | bottle |: 100% 1/1 [00:03<00:00,  3.15s/it]\n","bottle  test image ROCAUC: 0.640\n","[0 0 0 ... 0 0 0]\n","[0.6969596  0.6966578  0.6959741  ... 0.4891967  0.4905053  0.49113446]\n","bottle  test pixel ROCAUC: 0.858\n","Training..\n","| feature extraction | train | cable |: 100% 2/2 [00:12<00:00,  6.06s/it]\n","| feature extraction | test | cable |:   0% 0/2 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:4358: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:4296: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.\n","  warnings.warn(\n","| feature extraction | test | cable |: 100% 2/2 [00:08<00:00,  4.31s/it]\n","cable  test image ROCAUC: 0.756\n","[0 0 0 ... 0 0 0]\n","[0.66341287 0.6615864  0.6578733  ... 0.16580318 0.16643299 0.1667627 ]\n","cable  test pixel ROCAUC: 0.917\n","Training..\n","| feature extraction | train | capsule |: 100% 2/2 [00:11<00:00,  5.62s/it]\n","| feature extraction | test | capsule |:   0% 0/2 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:4358: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:4296: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.\n","  warnings.warn(\n","| feature extraction | test | capsule |: 100% 2/2 [00:07<00:00,  3.82s/it]\n","capsule  test image ROCAUC: 0.622\n","[0 0 0 ... 0 0 0]\n","[0.59599555 0.5975302  0.60051113 ... 0.55018127 0.54962444 0.5492891 ]\n","capsule  test pixel ROCAUC: 0.946\n","Training..\n","| feature extraction | train | carpet |: 100% 3/3 [00:14<00:00,  4.91s/it]\n","| feature extraction | test | carpet |:   0% 0/1 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:4358: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:4296: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.\n","  warnings.warn(\n","| feature extraction | test | carpet |: 100% 1/1 [00:06<00:00,  6.72s/it]\n","carpet  test image ROCAUC: 0.982\n","[0 0 0 ... 0 0 0]\n","[0.0870729  0.08860575 0.09158951 ... 0.15204832 0.15180206 0.15166657]\n","carpet  test pixel ROCAUC: 0.991\n","Training..\n","| feature extraction | train | grid |: 100% 3/3 [00:07<00:00,  2.36s/it]\n","| feature extraction | test | grid |:   0% 0/1 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:4358: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:4296: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.\n","  warnings.warn(\n","| feature extraction | test | grid |: 100% 1/1 [00:02<00:00,  2.65s/it]\n","grid  test image ROCAUC: 0.921\n","[0 0 0 ... 0 0 0]\n","[0.12021022 0.12034595 0.12069921 ... 0.06001448 0.0562762  0.05433361]\n","grid  test pixel ROCAUC: 0.941\n","Training..\n","| feature extraction | train | hazelnut |: 100% 4/4 [00:19<00:00,  4.94s/it]\n","| feature extraction | test | hazelnut |:   0% 0/1 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:4358: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:4296: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.\n","  warnings.warn(\n","| feature extraction | test | hazelnut |: 100% 1/1 [00:06<00:00,  6.05s/it]\n","hazelnut  test image ROCAUC: 0.679\n","[0 0 0 ... 0 0 0]\n","[0.67767763 0.6742184  0.6675798  ... 0.03681848 0.03660499 0.03648359]\n","hazelnut  test pixel ROCAUC: 0.961\n","Training..\n","| feature extraction | train | leather |: 100% 2/2 [00:11<00:00,  5.57s/it]\n","| feature extraction | test | leather |:   0% 0/1 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:4358: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:4296: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.\n","  warnings.warn(\n","| feature extraction | test | leather |: 100% 1/1 [00:06<00:00,  6.58s/it]\n","leather  test image ROCAUC: 0.999\n","[0 0 0 ... 0 0 0]\n","[0.08052483 0.0804852  0.08036    ... 0.03460314 0.0351119  0.03536507]\n","leather  test pixel ROCAUC: 0.990\n","Training..\n","| feature extraction | train | metal_nut |: 100% 2/2 [00:05<00:00,  2.95s/it]\n","| feature extraction | test | metal_nut |:   0% 0/1 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:4358: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:4296: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.\n","  warnings.warn(\n","| feature extraction | test | metal_nut |: 100% 1/1 [00:03<00:00,  3.41s/it]\n","metal_nut  test image ROCAUC: 0.802\n","[0 0 0 ... 0 0 0]\n","[5.0415772e-01 5.0242591e-01 4.9887761e-01 ... 3.4291614e-04 2.9330485e-04\n"," 2.6523077e-04]\n","metal_nut  test pixel ROCAUC: 0.927\n","Training..\n","| feature extraction | train | pill |: 100% 3/3 [00:09<00:00,  3.05s/it]\n","| feature extraction | test | pill |:   0% 0/2 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:4358: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:4296: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.\n","  warnings.warn(\n","| feature extraction | test | pill |: 100% 2/2 [00:06<00:00,  3.21s/it]\n","pill  test image ROCAUC: 0.741\n","[0 0 0 ... 0 0 0]\n","[0.0660575  0.06613814 0.06630169 ... 0.28021142 0.27733308 0.27577594]\n","pill  test pixel ROCAUC: 0.851\n","Training..\n","| feature extraction | train | screw |: 100% 3/3 [00:08<00:00,  2.84s/it]\n","| feature extraction | test | screw |:   0% 0/2 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:4358: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:4296: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.\n","  warnings.warn(\n","| feature extraction | test | screw |:  50% 1/2 [00:04<00:04,  4.36s/it]\n","Traceback (most recent call last):\n","  File \"/content/my_drive/MyDrive/Neurips23/Integrating-Spatial-Transform-Networks-with-PaDim-Architecture/notebooks/train_padim.py\", line 75, in <module>\n","    main_process()\n","  File \"/content/my_drive/MyDrive/Neurips23/Integrating-Spatial-Transform-Networks-with-PaDim-Architecture/notebooks/train_padim.py\", line 74, in main_process\n","    train(args)\n","  File \"/content/my_drive/MyDrive/Neurips23/Integrating-Spatial-Transform-Networks-with-PaDim-Architecture/notebooks/train_padim.py\", line 64, in train\n","    fig_pixel_rocauc,fig_img_rocauc,total_roc_auc,total_pixel_roc_auc,fig = padim_train.start(CLASS_NAMES,\n","  File \"/content/my_drive/MyDrive/Neurips23/Integrating-Spatial-Transform-Networks-with-PaDim-Architecture/notebooks/../src/padim_model/train.py\", line 208, in start\n","    for (x, y, mask) in tqdm(test_dataloader, '| feature extraction | test | %s |' % class_name):\n","  File \"/usr/local/lib/python3.10/dist-packages/tqdm/std.py\", line 1182, in __iter__\n","    for obj in iterable:\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 630, in __next__\n","    data = self._next_data()\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 674, in _next_data\n","    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\", line 51, in fetch\n","    data = [self.dataset[idx] for idx in possibly_batched_index]\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\", line 51, in <listcomp>\n","    data = [self.dataset[idx] for idx in possibly_batched_index]\n","  File \"/content/my_drive/MyDrive/Neurips23/Integrating-Spatial-Transform-Networks-with-PaDim-Architecture/notebooks/../src/padim_model/dataloader.py\", line 39, in __getitem__\n","    x = cv2.imread(x)\n","KeyboardInterrupt\n","Traceback (most recent call last):\n","  File \"/content/my_drive/MyDrive/Neurips23/Integrating-Spatial-Transform-Networks-with-PaDim-Architecture/notebooks/train_padim.py\", line 75, in <module>\n","    main_process()\n","  File \"/content/my_drive/MyDrive/Neurips23/Integrating-Spatial-Transform-Networks-with-PaDim-Architecture/notebooks/train_padim.py\", line 74, in main_process\n","    train(args)\n","  File \"/content/my_drive/MyDrive/Neurips23/Integrating-Spatial-Transform-Networks-with-PaDim-Architecture/notebooks/train_padim.py\", line 64, in train\n","    fig_pixel_rocauc,fig_img_rocauc,total_roc_auc,total_pixel_roc_auc,fig = padim_train.start(CLASS_NAMES,\n","  File \"/content/my_drive/MyDrive/Neurips23/Integrating-Spatial-Transform-Networks-with-PaDim-Architecture/notebooks/../src/padim_model/train.py\", line 208, in start\n","    for (x, y, mask) in tqdm(test_dataloader, '| feature extraction | test | %s |' % class_name):\n","  File \"/usr/local/lib/python3.10/dist-packages/tqdm/std.py\", line 1182, in __iter__\n","    for obj in iterable:\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 630, in __next__\n","    data = self._next_data()\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 674, in _next_data\n","    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\", line 51, in fetch\n","    data = [self.dataset[idx] for idx in possibly_batched_index]\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\", line 51, in <listcomp>\n","    data = [self.dataset[idx] for idx in possibly_batched_index]\n","  File \"/content/my_drive/MyDrive/Neurips23/Integrating-Spatial-Transform-Networks-with-PaDim-Architecture/notebooks/../src/padim_model/dataloader.py\", line 39, in __getitem__\n","    x = cv2.imread(x)\n","KeyboardInterrupt\n","/usr/lib/python3.10/multiprocessing/resource_tracker.py:224: UserWarning: resource_tracker: There appear to be 1 leaked semaphore objects to clean up at shutdown\n","  warnings.warn('resource_tracker: There appear to be %d '\n","\u001b[34m\u001b[1mwandb\u001b[0m: \n","\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n","\u001b[34m\u001b[1mwandb\u001b[0m:    bottle_image_ROCAUC ▁\n","\u001b[34m\u001b[1mwandb\u001b[0m:    bottle_pixel_ROCAUC ▁\n","\u001b[34m\u001b[1mwandb\u001b[0m:     cable_image_ROCAUC ▁\n","\u001b[34m\u001b[1mwandb\u001b[0m:     cable_pixel_ROCAUC ▁\n","\u001b[34m\u001b[1mwandb\u001b[0m:   capsule_image_ROCAUC ▁\n","\u001b[34m\u001b[1mwandb\u001b[0m:   capsule_pixel_ROCAUC ▁\n","\u001b[34m\u001b[1mwandb\u001b[0m:    carpet_image_ROCAUC ▁\n","\u001b[34m\u001b[1mwandb\u001b[0m:    carpet_pixel_ROCAUC ▁\n","\u001b[34m\u001b[1mwandb\u001b[0m:      grid_image_ROCAUC ▁\n","\u001b[34m\u001b[1mwandb\u001b[0m:      grid_pixel_ROCAUC ▁\n","\u001b[34m\u001b[1mwandb\u001b[0m:  hazelnut_image_ROCAUC ▁\n","\u001b[34m\u001b[1mwandb\u001b[0m:  hazelnut_pixel_ROCAUC ▁\n","\u001b[34m\u001b[1mwandb\u001b[0m:   leather_image_ROCAUC ▁\n","\u001b[34m\u001b[1mwandb\u001b[0m:   leather_pixel_ROCAUC ▁\n","\u001b[34m\u001b[1mwandb\u001b[0m: metal_nut_image_ROCAUC ▁\n","\u001b[34m\u001b[1mwandb\u001b[0m: metal_nut_pixel_ROCAUC ▁\n","\u001b[34m\u001b[1mwandb\u001b[0m:      pill_image_ROCAUC ▁\n","\u001b[34m\u001b[1mwandb\u001b[0m:      pill_pixel_ROCAUC ▁\n","\u001b[34m\u001b[1mwandb\u001b[0m: \n","\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n","\u001b[34m\u001b[1mwandb\u001b[0m:    bottle_image_ROCAUC 0.63968\n","\u001b[34m\u001b[1mwandb\u001b[0m:    bottle_pixel_ROCAUC 0.858\n","\u001b[34m\u001b[1mwandb\u001b[0m:     cable_image_ROCAUC 0.75637\n","\u001b[34m\u001b[1mwandb\u001b[0m:     cable_pixel_ROCAUC 0.91673\n","\u001b[34m\u001b[1mwandb\u001b[0m:   capsule_image_ROCAUC 0.62226\n","\u001b[34m\u001b[1mwandb\u001b[0m:   capsule_pixel_ROCAUC 0.94623\n","\u001b[34m\u001b[1mwandb\u001b[0m:    carpet_image_ROCAUC 0.98194\n","\u001b[34m\u001b[1mwandb\u001b[0m:    carpet_pixel_ROCAUC 0.99097\n","\u001b[34m\u001b[1mwandb\u001b[0m:      grid_image_ROCAUC 0.92063\n","\u001b[34m\u001b[1mwandb\u001b[0m:      grid_pixel_ROCAUC 0.94074\n","\u001b[34m\u001b[1mwandb\u001b[0m:  hazelnut_image_ROCAUC 0.67893\n","\u001b[34m\u001b[1mwandb\u001b[0m:  hazelnut_pixel_ROCAUC 0.96129\n","\u001b[34m\u001b[1mwandb\u001b[0m:   leather_image_ROCAUC 0.99898\n","\u001b[34m\u001b[1mwandb\u001b[0m:   leather_pixel_ROCAUC 0.99007\n","\u001b[34m\u001b[1mwandb\u001b[0m: metal_nut_image_ROCAUC 0.80205\n","\u001b[34m\u001b[1mwandb\u001b[0m: metal_nut_pixel_ROCAUC 0.92722\n","\u001b[34m\u001b[1mwandb\u001b[0m:      pill_image_ROCAUC 0.74113\n","\u001b[34m\u001b[1mwandb\u001b[0m:      pill_pixel_ROCAUC 0.8512\n","\u001b[34m\u001b[1mwandb\u001b[0m: \n","\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mexp-padim\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/ml_projects/neurips_23_padim/runs/57gnqllf\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: ️⚡ View job at \u001b[34m\u001b[4mhttps://wandb.ai/ml_projects/neurips_23_padim/jobs/QXJ0aWZhY3RDb2xsZWN0aW9uOjEyMjQ1MzU5Nw==/version_details/v1\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 9 media file(s), 2 artifact file(s) and 0 other file(s)\n","\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20231210_191833-57gnqllf/logs\u001b[0m\n","^C\n"]}],"source":["! python train_padim.py --arch resnet18 --use_stn_mask 1 --use_stn 1 --path_model_stn ../results/models/v1_mse/checkpoint_best_model_ssim_weight_08.pth"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FZxaU7v9wiC0","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1702236686617,"user_tz":300,"elapsed":13006,"user":{"displayName":"Cristian Lazo","userId":"16455738793233122743"}},"outputId":"c31f6f20-fa6b-407d-d1e5-4ea992b066ae"},"outputs":[{"output_type":"stream","name":"stdout","text":["Exception ignored in: <function _xla_gc_callback at 0x78df7786c280>\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/jax/_src/lib/__init__.py\", line 101, in _xla_gc_callback\n","    def _xla_gc_callback(*args):\n","KeyboardInterrupt: \n","args.device: 0\n","Namespace(data_path='../data', experiment_name='exp-padim', batch_size=128, learning_rate=0.0005, path_results='../results/padim_results', arch='wide_resnet50_2', use_stn=0, use_stn_mask=0, path_model_stn='../results/models/v1_mse/checkpoint_best_model_ssim_weight_08.pth', device='0')\n","\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mcristian-ml\u001b[0m (\u001b[33mml_projects\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.1\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/my_drive/MyDrive/Neurips23/Integrating-Spatial-Transform-Networks-with-PaDim-Architecture/notebooks/wandb/run-20231210_193119-5yiw5mzf\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mexp-padim\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/ml_projects/neurips_23_padim\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/ml_projects/neurips_23_padim/runs/5yiw5mzf\u001b[0m\n","/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=Wide_ResNet50_2_Weights.IMAGENET1K_V1`. You can also use `weights=Wide_ResNet50_2_Weights.DEFAULT` to get the most up-to-date weights.\n","  warnings.warn(msg)\n","Downloading: \"https://download.pytorch.org/models/wide_resnet50_2-95faca4d.pth\" to /root/.cache/torch/hub/checkpoints/wide_resnet50_2-95faca4d.pth\n","100% 132M/132M [00:01<00:00, 79.0MB/s]\n","/usr/lib/python3.10/multiprocessing/resource_tracker.py:224: UserWarning: resource_tracker: There appear to be 1 leaked semaphore objects to clean up at shutdown\n","  warnings.warn('resource_tracker: There appear to be %d '\n","^C\n"]}],"source":["!python train_padim.py --arch wide_resnet50_2 --use_stn_mask 0 --use_stn 0 --path_model_stn ../results/models/v1_mse/checkpoint_best_model_ssim_weight_08.pth"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gqlwDSOowPxY","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1702236689491,"user_tz":300,"elapsed":2876,"user":{"displayName":"Cristian Lazo","userId":"16455738793233122743"}},"outputId":"f335514f-3599-46d9-9db9-1a1e7411b784"},"outputs":[{"output_type":"stream","name":"stdout","text":["Traceback (most recent call last):\n","  File \"<frozen importlib._bootstrap>\", line 1027, in _find_and_load\n","  File \"<frozen importlib._bootstrap>\", line 992, in _find_and_load_unlocked\n","  File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\n","  File \"/usr/local/lib/python3.10/dist-packages/jax/__init__.py\", line 155, in <module>\n","    from jax import custom_batching as custom_batching\n","  File \"/usr/local/lib/python3.10/dist-packages/jax/custom_batching.py\", line 15, in <module>\n","    from jax._src.custom_batching import (\n","  File \"/usr/local/lib/python3.10/dist-packages/jax/_src/custom_batching.py\", line 19, in <module>\n","    from jax import lax\n","  File \"/usr/local/lib/python3.10/dist-packages/jax/lax/__init__.py\", line 378, in <module>\n","    from jax.lax import linalg as linalg\n","  File \"/usr/local/lib/python3.10/dist-packages/jax/lax/linalg.py\", line 15, in <module>\n","    from jax._src.lax.linalg import (\n","  File \"/usr/local/lib/python3.10/dist-packages/jax/_src/lax/linalg.py\", line 37, in <module>\n","    from jax._src.lax import eigh as lax_eigh\n","  File \"/usr/local/lib/python3.10/dist-packages/jax/_src/lax/eigh.py\", line 39, in <module>\n","    from jax._src.lax import qdwh\n","  File \"/usr/local/lib/python3.10/dist-packages/jax/_src/lax/qdwh.py\", line 31, in <module>\n","    import jax.numpy as jnp\n","  File \"/usr/local/lib/python3.10/dist-packages/jax/numpy/__init__.py\", line 424, in <module>\n","    from jax._src.numpy.array_methods import register_jax_array_methods\n","  File \"/usr/local/lib/python3.10/dist-packages/jax/_src/numpy/array_methods.py\", line 40, in <module>\n","    from jax._src.ops import scatter\n","  File \"<frozen importlib._bootstrap>\", line 1027, in _find_and_load\n","  File \"<frozen importlib._bootstrap>\", line 1006, in _find_and_load_unlocked\n","  File \"<frozen importlib._bootstrap>\", line 688, in _load_unlocked\n","  File \"<frozen importlib._bootstrap_external>\", line 879, in exec_module\n","  File \"<frozen importlib._bootstrap_external>\", line 984, in get_code\n","  File \"<frozen importlib._bootstrap_external>\", line 612, in _classify_pyc\n","KeyboardInterrupt\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/content/my_drive/MyDrive/Neurips23/Integrating-Spatial-Transform-Networks-with-PaDim-Architecture/notebooks/train_padim.py\", line 7, in <module>\n","    from src.padim_model import train as padim_train\n","  File \"/content/my_drive/MyDrive/Neurips23/Integrating-Spatial-Transform-Networks-with-PaDim-Architecture/notebooks/../src/padim_model/train.py\", line 3, in <module>\n","    from .model import *\n","  File \"/content/my_drive/MyDrive/Neurips23/Integrating-Spatial-Transform-Networks-with-PaDim-Architecture/notebooks/../src/padim_model/model.py\", line 1, in <module>\n","    from torchvision.models import wide_resnet50_2, resnet18\n","  File \"/usr/local/lib/python3.10/dist-packages/torchvision/__init__.py\", line 6, in <module>\n","    from torchvision import _meta_registrations, datasets, io, models, ops, transforms, utils\n","  File \"/usr/local/lib/python3.10/dist-packages/torchvision/models/__init__.py\", line 2, in <module>\n","    from .convnext import *\n","  File \"/usr/local/lib/python3.10/dist-packages/torchvision/models/convnext.py\", line 8, in <module>\n","    from ..ops.misc import Conv2dNormActivation, Permute\n","  File \"/usr/local/lib/python3.10/dist-packages/torchvision/ops/__init__.py\", line 1, in <module>\n","    from ._register_onnx_ops import _register_custom_op\n","  File \"/usr/local/lib/python3.10/dist-packages/torchvision/ops/_register_onnx_ops.py\", line 5, in <module>\n","    from torch.onnx import symbolic_opset11 as opset11\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/onnx/__init__.py\", line 46, in <module>\n","    from ._internal.exporter import (  # usort:skip. needs to be last to avoid circular import\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/onnx/_internal/exporter.py\", line 42, in <module>\n","    from torch.onnx._internal.fx import (\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/onnx/_internal/fx/__init__.py\", line 1, in <module>\n","    from .patcher import ONNXTorchPatcher\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/onnx/_internal/fx/patcher.py\", line 11, in <module>\n","    import transformers  # type: ignore[import]\n","  File \"/usr/local/lib/python3.10/dist-packages/transformers/__init__.py\", line 26, in <module>\n","    from . import dependency_versions_check\n","  File \"/usr/local/lib/python3.10/dist-packages/transformers/dependency_versions_check.py\", line 16, in <module>\n","    from .utils.versions import require_version, require_version_core\n","  File \"/usr/local/lib/python3.10/dist-packages/transformers/utils/__init__.py\", line 31, in <module>\n","    from .generic import (\n","  File \"/usr/local/lib/python3.10/dist-packages/transformers/utils/generic.py\", line 33, in <module>\n","    import jax.numpy as jnp\n","  File \"<frozen importlib._bootstrap>\", line 1027, in _find_and_load\n","KeyboardInterrupt\n","^C\n"]}],"source":["!python train_padim.py --arch wide_resnet50_2 --use_stn_mask 1 --use_stn 1 --path_model_stn ../results/models/v1_mse/checkpoint_best_model_ssim_weight_08.pth"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jTddfnF0lt6Q"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0LXYIebewsXD"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_VV4UU74wsUF"},"outputs":[],"source":[]}],"metadata":{"colab":{"machine_shape":"hm","provenance":[],"authorship_tag":"ABX9TyMXKAM9TCiH0v93hJ81TEQk"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}